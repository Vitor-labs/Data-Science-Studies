{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","\n","data = pd.read_csv('../Datasets/creditcard.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0    284315\n","1       492\n","Name: Class, dtype: int64\n"]}],"source":["# normalise the amount column\n","data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1))\n","\n","# drop Time and Amount columns as they are not relevant for prediction purpose\n","data = data.drop(['Time', 'Amount'], axis = 1)\n","\n","# as you can see there are 492 fraud transactions.\n","print(data['Class'].value_counts())"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0         0\n","1         0\n","2         0\n","3         0\n","4         0\n","         ..\n","284802    0\n","284803    0\n","284804    0\n","284805    0\n","284806    0\n","Name: Class, Length: 284807, dtype: int64\n"]}],"source":["X = data[:]\n","X = X.drop('Class', axis = 1)\n","\n","y = data['Class']"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number transactions X_train dataset:  (199364, 29)\n","Number transactions y_train dataset:  (199364,)\n","Number transactions X_test dataset:  (85443, 29)\n","Number transactions y_test dataset:  (85443,)\n"]}],"source":["# split into 70:30 ration\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n","\n","# describes info about train and test set\n","print(\"Number transactions X_train dataset: \", X_train.shape)\n","print(\"Number transactions y_train dataset: \", y_train.shape)\n","print(\"Number transactions X_test dataset: \", X_test.shape)\n","print(\"Number transactions y_test dataset: \", y_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Note:\n","The recall of the minority class in very less. It proves that the model is more biased towards majority class. So, it proves that this is not the best model.   "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     85296\n","           1       0.88      0.62      0.73       147\n","\n","    accuracy                           1.00     85443\n","   macro avg       0.94      0.81      0.86     85443\n","weighted avg       1.00      1.00      1.00     85443\n","\n"]}],"source":["# logistic regression object\n","lr = LogisticRegression()\n","\n","# train the model on train set\n","lr.fit(X_train, y_train.ravel())\n","\n","predictions = lr.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, predictions))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before OverSampling, counts of label '1': 345\n","Before OverSampling, counts of label '0': 199019 \n","\n","After OverSampling, the shape of train_X: (398038, 29)\n","After OverSampling, the shape of train_y: (398038,) \n","\n","After OverSampling, counts of label '1': 199019\n","After OverSampling, counts of label '0': 199019\n"]}],"source":["print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n","print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n","\n","# import SMOTE module from imblearn library\n","# pip install imblearn (if you don't have imblearn in your system)\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(random_state = 2)\n","X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n","\n","print(f'After OverSampling, the shape of train_X: {X_train_res.shape}')\n","print(f'After OverSampling, the shape of train_y: {y_train_res.shape} \\n')\n","\n","print(f\"After OverSampling, counts of label '1': {sum(y_train_res == 1)}\")\n","print(f\"After OverSampling, counts of label '0': {sum(y_train_res == 0)}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### LOOK:\n","SMOTE Algorithm has oversampled the minority instances and made it equal to majority class. Both categories have equal amount of records. More specifically, the minority class has been increased to the total number of majority class.\n","\n","The accuracy was reduced to 98%, but the recall value of minority class has also improved to 92 %. This is a good model compared to the previous one. Recall is great."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     85296\n","           1       0.06      0.92      0.11       147\n","\n","    accuracy                           0.98     85443\n","   macro avg       0.53      0.95      0.55     85443\n","weighted avg       1.00      0.98      0.99     85443\n","\n"]}],"source":["lr1 = LogisticRegression()\n","lr1.fit(X_train_res, y_train_res.ravel())\n","predictions = lr1.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, predictions))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before Undersampling, counts of label '1': 345\n","Before Undersampling, counts of label '0': 199019 \n","\n","After Undersampling, the shape of train_X: (690, 29)\n","After Undersampling, the shape of train_y: (690,) \n","\n","After Undersampling, counts of label '1': 345\n","After Undersampling, counts of label '0': 345\n"]}],"source":["print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1)))\n","print(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n","\n","# apply near miss\n","from imblearn.under_sampling import NearMiss\n","nr = NearMiss()\n","\n","X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel())\n","\n","print('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape))\n","print('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape))\n","\n","print(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1)))\n","print(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **LOOK**:\n","This model is better than the first model because it classifies better and also the recall value of minority class is 95 %. But due to undersampling of majority class, its recall has decreased to 55 %. So in this case, SMOTE is giving a great accuracy and recall"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.55      0.71     85296\n","           1       0.00      0.95      0.01       147\n","\n","    accuracy                           0.56     85443\n","   macro avg       0.50      0.75      0.36     85443\n","weighted avg       1.00      0.56      0.71     85443\n","\n"]}],"source":["# train the model on train set\n","lr2 = LogisticRegression()\n","lr2.fit(X_train_miss, y_train_miss.ravel())\n","predictions = lr2.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, predictions))"]}],"metadata":{"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"cb9c02bf58191defec3451b82afcb82bc4036187a304ee1bac7122b07deb8828"}}},"nbformat":4,"nbformat_minor":2}
